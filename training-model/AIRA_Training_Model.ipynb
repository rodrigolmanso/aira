{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIRA - Training Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U8SOw5eUFOx",
        "colab_type": "text"
      },
      "source": [
        "# AIRA - Inteligência Artificial para Prevenção de Acidentes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1L4vuEGn2_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('workflow.JPG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVgAN5fDUV0t",
        "colab_type": "text"
      },
      "source": [
        "## Problema - O Motorista está em risco de sofrer acidente?\n",
        "A análise de um conjunto de dados como hábitos do motorista, perfil de condução, região onde está trafegando, saúde mental, condições de descanso, entre outras, pode ajudar na prevenção de acidentes e na manutenção da vida.\n",
        "## Problema de Negócio\n",
        "**Objetivo** - Definir com 70% de precisão ou mais, o risco de acidente do motorista. Como não estamos lidando com dados reais, e nem todas as etapas de análise e treinamento do modelo foram realizadas, os resultados serão altamente distorcidos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFRC6wpaWZjq",
        "colab_type": "text"
      },
      "source": [
        "## Instalação e Importação das Bibliotecas\n",
        "Para este exemplo, faremos uma análise simples dos dados utilizando o classificador Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_kNNzCaY_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-plot \n",
        "!pip install dfply\n",
        "!pip install dtreeviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZi4-PtjdPi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvmTuTglWUyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from joblib import dump\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "from dfply import *\n",
        "from dtreeviz.trees import *\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report\n",
        "from IPython.display import display\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from IPython.display import Image\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwzPtEPrXZXW",
        "colab_type": "text"
      },
      "source": [
        "## Importando a Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfPViPD3XdsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregando o dataset\n",
        "df = pd.read_csv('aira_data.csv', sep = '|', encoding = 'latin-1') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CKPX74iXyZM",
        "colab_type": "text"
      },
      "source": [
        "## Análise Exploratória dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYgY9xPfX0UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificando o formato dos dados\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5bzVqd0X3sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificando as primeiras linhas do dataset\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz_zJqj7YwZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identificando a correlação entre as variáveis\n",
        "# Correlação não implica causalidade\n",
        "correlation_matrix = df.corr()\n",
        "plt.figure(figsize=(10,8))\n",
        "ax = sns.heatmap(correlation_matrix, vmax=1, square=True, annot=True,fmt='.2f', cmap ='GnBu', cbar_kws={\"shrink\": .5}, robust=True)\n",
        "plt.title('Matriz de correlação entre as variáveis', fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOJxDb8faI8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizando a correlação em tabela\n",
        "# Coeficiente de correlação: \n",
        "# +1  = forte correlação positiva\n",
        "# 0   = não há correlação\n",
        "# -1  = forte correlação negativa\n",
        "df.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI2oZ1umdv-F",
        "colab_type": "text"
      },
      "source": [
        "## Tratamento da Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyHRL4Zxd0A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificando se existem valores nulos\n",
        "df.isnull().values.any()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FMM0ZtWbF3k",
        "colab_type": "text"
      },
      "source": [
        "## Divisão da base de em atributos previsores e atributo classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fh_EwHHcoeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Atributos Previsores\n",
        "previsores = df.iloc[:, 0:-1]\n",
        "# Atributos Classe\n",
        "classe = df.iloc[:, -1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkW1k9qLeXRD",
        "colab_type": "text"
      },
      "source": [
        "##Treinamento da Base de Dados\n",
        "Uma das boas práticas no desenvolvimento de modelos de Machine Learning é separar a base em um conjunto de treino para treinar o modelo e outro de teste para validar os resultados do modelo. Essa separação é crucial a fim de identificar se o modelo não está “decorando” os resultados ao invés de aprender, o famoso overfitting.\n",
        "\n",
        "Sobreajuste (overfitting) ocorre quando o modelo gerado decora a base e quando confrontado com novos dados obtem baixo desempenho.\n",
        "Subajuste (underfitting), quando não consegue identificar nenhum padrão.\n",
        "Separa-se em 4 subconjuntos, \"previsores_treinamento\" com as variáveis de input para treino do modelo e \"classe_treinamento\" com os resultados de predição para treino, ambos serão utilizados mais tarde no método fit do modelo, \"previsores_teste\" com as variáveis de input para teste e \"classe_teste\" com os resultados da predição para testes.\n",
        "\n",
        "Serão separado 70% dos dados para treino e 30% para teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7hKS1UQeVDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('treinamento overview.JPG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFrby345eog2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.30, random_state=101)\n",
        "# Imprimindo os resultados\n",
        "print(\"{0:0.2f}% nos dados de treino\".format((len(previsores_treinamento)/len(df.index)) * 100))\n",
        "print(\"{0:0.2f}% nos dados de teste\".format((len(previsores_teste)/len(df.index)) * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2mmNP0Ugey2",
        "colab_type": "text"
      },
      "source": [
        "## Função Auxiliar para Execução dos Modelos de Classificação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ELw0oUev2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def runModel(model, previsores_treinamento, classe_treinamento, previsores_teste, classe_teste, confusion_matrix=False, normalizeCM=False, roc=True, plot_calibration=False, random_state=42, title=\"\", pos_label=1):\n",
        "    \"\"\"Função auxiliar para execução de modelos de classificação.\n",
        "    \n",
        "    Parâmetros:\n",
        "    \n",
        "    - model: modelo de classificação a ser executado\n",
        "    - previsores_treinamento: base de treinamento das variáveis preditoras\n",
        "    - classe_treinamento: base de treinamento da classe\n",
        "    - previsores_teste: base de teste das variáveis preditoras\n",
        "    - classe_teste: base de teste da classe\n",
        "    - confusion_matrix (default: True): exibir a matriz de confusão da classificação\n",
        "    - normalizeCM (default: False): define se a matriz de confusão será normalizada\n",
        "    - roc (default: True): define se será exibida a curva ROC para o classificador\n",
        "    - plot_calibration (default: True): define se será exibida a curva de calibração para o classificador\n",
        "    - title: define o título a ser exibido nos gráficos\n",
        "    - pos_label: indica qual o valor de classe_treinamento e classe_teste que representa a classe positiva. O valor default é 1. \n",
        "\n",
        "    \"\"\"\n",
        "    clf = model\n",
        "    name = title\n",
        "    clf.fit(previsores_treinamento, classe_treinamento)\n",
        "    y_pred = clf.predict(previsores_teste)\n",
        "        \n",
        "    if hasattr(clf, \"predict_proba\"):\n",
        "        prob_pos = clf.predict_proba(previsores_teste)\n",
        "    else:  # use decision function\n",
        "        prob_pos = clf.decision_function(previsores_teste)\n",
        "        prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
        "    if confusion_matrix:\n",
        "       skplt.metrics.plot_confusion_matrix(classe_teste, y_pred, normalize=normalizeCM, title=name)\n",
        "    if roc:\n",
        "       skplt.metrics.plot_roc(classe_teste, prob_pos, plot_micro=False, plot_macro=False, classes_to_plot=[1], title=name,figsize=(10,10))\n",
        "     \n",
        "            \n",
        "    prob_pos = prob_pos[:,1]\n",
        "    clf_score = brier_score_loss(classe_teste, prob_pos, pos_label=pos_label)\n",
        "    print(\"%s:\" % name)\n",
        "    print(\"\\tBrier: %1.3f\" % (clf_score))\n",
        "    print(\"\\tPrecision: %1.3f\" % precision_score(classe_teste, y_pred))\n",
        "    print(\"\\tRecall: %1.3f\" % recall_score(classe_teste, y_pred))\n",
        "    print(\"\\tF1: %1.3f\\n\" % f1_score(classe_teste, y_pred))\n",
        "        \n",
        "    if plot_calibration:\n",
        "      \n",
        "      fraction_of_positives, mean_predicted_value = \\\n",
        "                calibration_curve(classe_teste, prob_pos, n_bins=10)\n",
        "      plt.rcParams.update({'font.size': 22})\n",
        "      plt.rc('legend',**{'fontsize':22})\n",
        "      fig = plt.figure(3, figsize=(10, 10))\n",
        "      ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
        "      ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
        "      ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfeitamente calibrado\",)\n",
        "      ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
        "                     label=\"%s (%1.3f)\" % (name, clf_score))\n",
        "\n",
        "      ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
        "                     histtype=\"step\", lw=2)\n",
        "\n",
        "      ax1.set_ylabel(\"Fração de positivos\")\n",
        "      ax1.set_ylim([-0.05, 1.05])\n",
        "      ax1.legend(loc=\"lower right\")\n",
        "      ax1.set_title('Gráfico de Calibração  (reliability curve)')\n",
        "      \n",
        "      ax2.set_xlabel(\"Valor médio predito\")\n",
        "      ax2.set_ylabel(\"Quantidade\")\n",
        "      ax2.legend(loc=\"upper center\", ncol=2)\n",
        "      \n",
        "      for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
        "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
        "        item.set_fontsize(22)\n",
        "        \n",
        "      for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
        "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
        "        item.set_fontsize(22)\n",
        "      \n",
        "      plt.tight_layout()\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chaCANjCgp2-",
        "colab_type": "text"
      },
      "source": [
        "## Treinamento do Modelo utilizando o Naive Bayes para classificação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6CYU6TygpGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construindo e treinando o modelo\n",
        "# Modelo_V1 utilizando o classificador Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(previsores_treinamento, classe_treinamento.values.ravel())\n",
        "dump(nb_classifier, \"naive_bayes.joblib\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mELGt5_pe0Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificando a exatidão do modelo nos dados de teste\n",
        "from sklearn import metrics\n",
        "nb_predict_test = nb_classifier.predict(previsores_teste)\n",
        "print(\"Exatidão (Accuracy): {0:.4f}\".format(metrics.accuracy_score(classe_teste, nb_predict_test)))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGLQSTsMhlGu",
        "colab_type": "text"
      },
      "source": [
        "## Analisando os Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y8pbJsNheon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criando uma Confusion Matrix\n",
        "print(\"Confusion Matrix\")\n",
        "\n",
        "print(\"{0}\".format(metrics.confusion_matrix(classe_teste, nb_predict_test, labels = [1, 0])))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Classification Report\")\n",
        "print(metrics.classification_report(classe_teste, nb_predict_test, labels = [1, 0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6btjWyaho1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "previsoes = nb_classifier.predict_proba(previsores_teste)\n",
        "previsoes = pd.DataFrame(previsoes)\n",
        "classe_teste = np.array(classe_teste)\n",
        "classe_teste = classe_teste.reshape(-1,1)\n",
        "classe_teste.shape\n",
        "classe_teste = pd.DataFrame(classe_teste)\n",
        "previsoes_concat =  pd.concat([previsoes,classe_teste], axis=1)\n",
        "previsoes_concat.columns=['Com Risco','Sem Risco','Classe']\n",
        "previsoes_concat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WCumaOSi3e6",
        "colab_type": "text"
      },
      "source": [
        "## Análise da Curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z0pqmd7iKpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_classifier = GaussianNB()\n",
        "runModel(nb_classifier, previsores_treinamento, classe_treinamento, previsores_teste, classe_teste, title=\"Naive Bayes\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}